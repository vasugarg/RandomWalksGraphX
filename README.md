# Random Walks on graphs using GraphX and Pregel
Random Walks on Graphx using Pregel

### Author: Vasu Garg
### Email: vasug20@gmail.com

## Introduction

This project contains a Spark application that uses the GraphX library to perform a random walk on graphs using the Pregel API. The application performs dynamic matching of vertex values during the random walk process.

Video Link: https://youtu.be/SCRUelYObEw
The video explains deployment of hadoop application in AWS EMR Cluster and the project structure

## Prerequisites

- JDK 8
- Apache Spark 3.4.0 or above
- Scala 2.13.x
- SBT (Scala Build Tool)

### Running the test cases

Test Files can be found under the directory src/test

````
sbt clean compile test
````

### Running the project

1) Clone this repository

```
git clone https://github.com/vasugarg/RandomWalksGraphX
```
2) cd to the Project
```
cd RandomWalksGraphX
```

3) Open the project in intelliJ
```
https://www.jetbrains.com/help/idea/import-project-or-module-wizard.html#open-project
```
4) Open application.conf under src/main/resources/application.conf and make sure the relevant folders are created in the project. Below is the explanation of the configuration settings that needs to be set for the program to run.

##### Configuration Settings (application.conf)

- **`originalGraphFilePath`**
  - **Purpose:** Sets the filepath for the original graph from which we need to take out the valuable nodes.

- **`perturbedGraphFilePath`**
  - **Purpose:** Specifies the filepath for the perturbed graph on which we will perform the random walks.

- **`yamlFilePath`**
  - **Purpose:** Sets the path to a YAML file associated with the application.

- **Paths and Directories:**
  - Note that certain settings specify directory paths relative to the project's root directory.
  - For example, if `yamlFilePath` is set to `"src/main/resources"`, it refers to the `src/main/resources` directory within the project's root directory.
  - These relative paths are resolved based on the project's classpath, providing flexibility and independence from specific absolute file paths.
  - The `src/main/resources/` folder already contains sample graph generated by setting the number of states as 300 which can be used to run the program.
  - In order to run the program on different graphs, you can clone NetGameSime and call Main class to generate new graphs and making the relevant changes to application.conf post that.
  - For deploying in AWS, we need to use the configurations under `RandomWalksGraphX.FilePathsAWS` section.

5) Running project via SBT Run.
```
sbt run
```
6) (Optional) The application can be run on a Spark cluster or locally using the spark-submit command:
```
spark-submit --class cs441.HW2.Main --master local[4] target/scala-2.12/random-walkers_2.13-12.jar <input_file>
```

## Project Structure

The project comprises the following key components:

- **GraphX Loaders**: GraphX library is used to generate graphX graphs, by converting the nodes and edges returned from the deserialisation of the NGS file into spark RDDs.

- **Pregel Implementation**: We use Google's Pregel library on the generated GaphX graphs to perform the Random Walks. More details on the imlplementation are present in the below section.

- **Similarity Score**: The project employs the Jaccard Index to calculate the similarity score between nodes and edges.
- **Attack Handler**: This program iterates over each random walk and based on the similaroty scores, it decides whether to attack or leave a random walk.

## Pregel Implementation
- **Vertex Program**: This function runs on each vertex and receives messages from the previous iteration. The state of each vertex can be updated based on these messages. In our application, this function checks for incoming walkers and updates their paths according to the vertex's own data and the dynamic matcher value.

- **Sending Messages**: After the vertex program, messages are generated for the next iteration. In the context of our random walks, the vertices send messages along their outgoing edges to propagate the walk.

- **Message Combiner**: Messages destined for the same vertex are combined to streamline processing. For our random walk, this might involve merging paths or matcher values.

## Logging
We are using custom log4j.properties under src/main/resources to redirect the logs for the spark application to logs/ folder. Make sure to create the folder if not already present

## Conclusion

This project demonstrates the power of Apache Spark and libraries like GraphX and Pregel in implementing a solution for distributed processing and analyzing large graphs.

**Note:** This README provides an overview of the project. For detailed documentation and instructions, refer to the project's youtube video link and src files.
